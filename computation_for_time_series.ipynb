{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu+/mbcNy39yNkfM0mZkew",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/q-vietle/simulation/blob/main/computation_for_time_series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2**"
      ],
      "metadata": {
        "id": "koQ_MQTpeyJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "ns-0nFGffSrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''data processing'''\n",
        "import statsmodels.tsa.stattools as stats\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "df = np.loadtxt(fname='', dtype='float')\n",
        "time = np.arange(df.shape[0])"
      ],
      "metadata": {
        "id": "W7_wuLAGfULx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''remove data trend'''\n",
        "\n",
        "def poly_fit(x,y,degree):\n",
        "  designed_matrix = sm.add_constant(np.vander(x, degree+1, increasing= False)[:,:-1])\n",
        "  model = sm.OLS(y, designed_matrix)\n",
        "  results = model.fit()\n",
        "  trend = results.predict(designed_matrix)\n",
        "  residual = y - trend\n",
        "  trend_model = results.params\n",
        "  return residual, trend, trend_model\n",
        "\n",
        "'''main'''\n",
        "deg =\n",
        "residual, trend, trend_model = poly_fit(time,df,deg)"
      ],
      "metadata": {
        "id": "uxmGQXWhfVkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''find out cut-off'''\n",
        "\n",
        "import scipy.stats as stats\n",
        "def z_crit(alpha_level = 0.5):\n",
        "  z = stats.norm.ppf(1 - alpha_level/2)\n",
        "  return z\n",
        "alpha_level =\n",
        "z_crit = z_crit(alpha_level)"
      ],
      "metadata": {
        "id": "iZNScWoIevkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bartlett formula**\n",
        "\n",
        "AR\n",
        "W[lag,lag] = (1-phi^(2*lag))*(1+phi^2)/(1-phi^2)-2*lag*phi^(2*lag)\n",
        "\n",
        "MA\n",
        "W[lag,lag] = sum(rho(i+lag)+rho(lag-i)-2rho(lag)*rho(i))^2 for i from 0 to inf"
      ],
      "metadata": {
        "id": "mNg1KEoCbi8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''MA hypothesis'''\n",
        "\n",
        "n = residual.shape[0]\n",
        "def hypothesis_for_MA(residual, lag = 1, order = 1):\n",
        "  acf = sm.tsa.acf(residual, nlags=40)\n",
        "  W = #bartlett formula\n",
        "  T_test = (W/n)**(-1/2)*acf[lag]\n",
        "  p_value = stats.norm.cdf(T_test)\n",
        "  lb,ub = acf[lag]-z_crit*(W/n)**(1/2),acf[lag]+z_crit*(W/n)**(1/2)\n",
        "  return T_test,p_value,lb,ub\n",
        "lag =\n",
        "order =\n",
        "T_test,p_value,lb,ub = hypothesis_for_MA(residual, lag, order)\n",
        "print(f'confidence interval at lag {lag}',(lb,ub))"
      ],
      "metadata": {
        "id": "c-CyFs3vfpSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''AR hypothesis'''\n",
        "\n",
        "n = residual.shape[0]\n",
        "def hypothesis_for_AR(residual, lag = 1, order = 1):\n",
        "  acf = sm.tsa.acf(residual, nlags=40)\n",
        "  phi = acf[1]\n",
        "  W = (1-phi**(2*lag))*(1+phi**2)/(1-phi**2)-2*lag*phi**(2*lag)#bartlett formula\n",
        "  T_test = (W/n)**(-1/2)*(acf[lag]-acf[1]**lag)\n",
        "  p_value = stats.norm.cdf(T_test)\n",
        "  lb,ub = acf[lag]-acf[1]**lag-z_crit*(W/n)**(1/2),acf[lag]-acf[1]**lag+z_crit*(W/n)**(1/2)\n",
        "  return T_test,p_value,lb,ub\n",
        "\n",
        "\n",
        "lag =\n",
        "order =\n",
        "T_test,p_value,lb,ub = hypothesis_for_AR(residual, lag, order)\n",
        "print(f'confidence interval at lag {lag}',(lb,ub))"
      ],
      "metadata": {
        "id": "Gd3ghFzRfbUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 4**"
      ],
      "metadata": {
        "id": "Nen_BjYvyI2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "_hNT3DcqyH_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''data processing'''\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "df = np.loadtxt(fname='', dtype='float')\n",
        "time = np.arange(df.shape[0])"
      ],
      "metadata": {
        "id": "JmgfhioUyUGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''remove multidimensional data trend '''\n",
        "\n",
        "def poly_fit(time, data, degree):\n",
        "    residuals = []\n",
        "    trends = []\n",
        "    for i in range(data.shape[1]):\n",
        "        y = data[:, i]\n",
        "        X = np.vander(time, degree+1, increasing=False)[:, :-1]\n",
        "        X = np.concatenate((np.ones((X.shape[0],1)), X), axis=1)\n",
        "        beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
        "        trend = X @ beta\n",
        "        residual = y - trend\n",
        "        residuals.append(residual)\n",
        "        trends.append(trend)\n",
        "    return np.column_stack(residuals), np.column_stack(trends)\n",
        "\n",
        "'''main'''\n",
        "time = time\n",
        "data = df\n",
        "degree =\n",
        "residuals, trends = poly_fit(time, data, degree)"
      ],
      "metadata": {
        "id": "jUFb_77KzUja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Log likelihood'''\n",
        "\n",
        "from statsmodels.tsa.statespace.varmax import VARMAX\n",
        "\n",
        "def ARMA_logLikelihood(residuals, order = (1,1)):\n",
        "  model = VARMAX(residuals, order = order, trend = None)\n",
        "  results = model.fit(maxiter=100)\n",
        "  logL = model.loglike(results.params)\n",
        "  return logL\n"
      ],
      "metadata": {
        "id": "Sn7rXIun0Bd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Information criteria'''\n",
        "\n",
        "def ARMA_IC(residuals, order=(1,1)):\n",
        "    logL = ARMA_logLikelihood(residuals, order = order)\n",
        "    p = order[0]\n",
        "    q = order[1]\n",
        "    n = len(residuals)\n",
        "    d = residuals.shape[1]\n",
        "    k = d**2*(p+q)+d*(d+1)/2\n",
        "    AIC = -2*logL+ 2*k\n",
        "    AIC_c = -2*logL+k*n/(n-k-1)\n",
        "    BIC = -2*logL+k*np.log(n)\n",
        "    return AIC, AIC_c, BIC\n",
        "\n",
        "def print_IC(residuals, p=[], q=[]):\n",
        "    for i in p:\n",
        "        for j in q:\n",
        "            order = (i,j)\n",
        "            AIC, AICc, BIC = ARMA_IC(residuals, order=order)\n",
        "            print(f'AIC, AICc, BIC of ARMA({i},{j}) are respectively', AIC, AICc, BIC)\n",
        "\n",
        "\n",
        "'''main'''\n",
        "p =\n",
        "q =\n",
        "print_IC(residuals, p, q)"
      ],
      "metadata": {
        "id": "7eCErjX41m6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''fit data into ARMA by VARMAX'''\n",
        "p =\n",
        "q =\n",
        "steps =\n",
        "model = VARMAX(residuals, order = (p,q), trend = None)\n",
        "results = model.fit(maxiter=100)\n",
        "next_residual = results.forecast(steps = steps)\n",
        "print('the next residual is',next_residual)\n",
        "\n",
        "model = VARMAX(df, order = (p,q), trend = None)\n",
        "results = model.fit(maxiter=100)\n",
        "next_value = results.forecast(steps = steps)\n",
        "print('the next value is', next_value)"
      ],
      "metadata": {
        "id": "3NskKvUz1qli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 6**"
      ],
      "metadata": {
        "id": "Ess7ACg-yV6L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6r32TJMeQmC"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''data processing'''\n",
        "\n",
        "import statsmodels.tsa.stattools as stats\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "df = np.loadtxt(fname='', dtype='float')\n",
        "time = np.arange(df.shape[0])"
      ],
      "metadata": {
        "id": "1e-zctLUeUSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''remove data trend'''\n",
        "\n",
        "def poly_fit(x,y,degree):\n",
        "  designed_matrix = sm.add_constant(np.vander(x, degree+1, increasing= False)[:,:-1])\n",
        "  model = sm.OLS(y, designed_matrix)\n",
        "  results = model.fit()\n",
        "  trend = results.predict(designed_matrix)\n",
        "  residual = y - trend\n",
        "  trend_model = results.params\n",
        "  return residual, trend, trend_model\n",
        "\n",
        "'''main'''\n",
        "deg =\n",
        "residual, trend, trend_model = poly_fit(time,df,deg)"
      ],
      "metadata": {
        "id": "ZY5HLOwq9Uuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''periodogram'''\n",
        "\n",
        "from scipy.signal import periodogram\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
        "freq, per = periodogram(residual)\n",
        "ax.plot(freq,per)\n"
      ],
      "metadata": {
        "id": "JMPaYdNh-Dy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''dominance frequency'''\n",
        "\n",
        "dom_freq = freq[np.argmax(per)]\n",
        "print(dom_freq)"
      ],
      "metadata": {
        "id": "vbNbvcDeAC-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''remove dominant frequency by MA filter'''\n",
        "\n",
        "from scipy.signal import convolve\n",
        "def periodogram_ma_filter(residual):\n",
        "  freq, per = periodogram(residual)\n",
        "  dom_freq = freq[np.argmax(per)]\n",
        "  dom_per = round(1/dom_freq)\n",
        "  ma_filter = np.ones(dom_per)*dom_freq\n",
        "  ma_filtered = convolve(residual, ma_filter, mode = 'same')\n",
        "  freq, per = periodogram(ma_filtered)\n",
        "  return ma_filtered, freq, per\n",
        "\n",
        "'''main'''\n",
        "residual_ma_filtered, ma_freq, ma_per = periodogram_ma_filter(residual)\n",
        "ax.plot(ma_freq,ma_per)\n"
      ],
      "metadata": {
        "id": "iMXLiLbhARye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''find coefficients of low-pass filter and low_pass_filter'''\n",
        "\n",
        "def low_pass_filter(num_of_coeffs, cut_off = float):\n",
        "  coeffs = []\n",
        "  num_of_coeffs = int(num_of_coeffs)\n",
        "  if num_of_coeffs == 1:\n",
        "    coeffs.append(cut_off/np.pi)\n",
        "  else:\n",
        "    coeffs.append(cut_off/np.pi)\n",
        "    for i in range(num_of_coeffs):\n",
        "      coeffs.append(np.sin((i+1)*cut_off)/((i+1)*np.pi))\n",
        "  coeffs = np.array(coeffs)\n",
        "  coeffs = np.concatenate((coeffs[::-1], coeffs[1:]))\n",
        "  return coeffs\n",
        "\n",
        "def periodogram_low_pass_filter(residual,size = int, cut_off = float):\n",
        "  lp_filter = low_pass_filter((size-1)/2, cut_off)\n",
        "  lp_filtered = convolve(residual, lp_filter, mode ='same')\n",
        "  freq, per = periodogram(lp_filtered)\n",
        "  return lp_filtered, freq, per\n",
        "\n",
        "'''main'''\n",
        "number_of_coeffs =\n",
        "size = #odd number\n",
        "desired_period =\n",
        "desired_freq = 1/desired_period\n",
        "cut_off = 2*np.pi*desired_freq\n",
        "\n",
        "print(low_pass_filter(number_of_coeffs, cut_off))\n",
        "residual_lp_filtered, lp_freq, lp_per = periodogram_low_pass_filter(residual, size, cut_off)\n",
        "\n",
        "ax.plot(lp_freq,lp_per)"
      ],
      "metadata": {
        "id": "yWc4M1B2F1DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''forecast residuals by ARIMA'''\n",
        "\n",
        "import statsmodels.tsa.arima.model as ARIMA\n",
        "\n",
        "def forecast_residual(residual, num_of_next_residual = 1, order = (1, 0, 1)):\n",
        "    model = sm.tsa.ARIMA(residual, order=order, trend = None)\n",
        "    results = model.fit()\n",
        "    next_residual = results.forecast(steps = num_of_next_residual)\n",
        "    return next_residual\n",
        "\n",
        "'''main'''\n",
        "\n",
        "p =\n",
        "q =\n",
        "num_of_next_residual =\n",
        "order = (p, 0, q)\n",
        "\n",
        "predicted_residuals = forecast_residual(residual, num_of_next_residual, order)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.append(residual,predicted_residuals)[-100:])\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "rkzP65L7OZlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''forecast values by ARIMA'''\n",
        "\n",
        "def forecast_value(trend_model,residual, num_of_next_residual = 1, order = (1, 0, 1)):\n",
        "  predicted_residual = forecast_residual(residual, num_of_next_residual, order)\n",
        "  trend_next = np.array([num_of_next_residual,residual.shape[0]]) @ trend_model\n",
        "  predicted_value = trend_next + predicted_residual\n",
        "  return predicted_value\n",
        "\n",
        "'''main'''\n",
        "\n",
        "p =\n",
        "q =\n",
        "num_of_next_residual =\n",
        "order = (p, 0, q)\n",
        "\n",
        "predicted_values = forecast_value(trend_model,residual, num_of_next_residual, order)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.append(df,predicted_values)[-100:])\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "-5ElHr4SV-b_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}